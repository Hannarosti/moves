---
title: "HMMs"
author: "jmm"
date: "10/2/2020"
output:
  bookdown::html_document2:
    css: style.css
    number_sections: false
    theme: default
    highlight: haddock
    toc: true
    toc_float: true
bibliography: moves.bib
csl: ecology.csl
---

```{r, echo=FALSE}
library(knitr)
library(bookdown)
options(figure_counter = FALSE, digits = 2, width = 150)
opts_knit$set(eval.after='fig.cap')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), 
                      echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE, 
                      cache = TRUE,
                      fig.width=12, fig.height=4.5)
```


## Hidden Markov Models[^1]

Many movement models proposed in recent years belong to the class of hidden Markov models (HMMs). An HMM is a time series model that comprises two components, an observable series and an underlying, non-observable state sequence (just as we saw with the mixture model). The observed data are taken to be conditionally independent given the states and are generated by *so-called* state-dependent distributions.

[^1]: Some of the code presented here has been moddified from @leosbarajas2018  https://arxiv.org/abs/1806.10639

The state sequence is modelled as a Markov process usually assumed to be of first order, which means that the probability of state occurrences at time $t+1$ depends only on which state the chain is in at time $t$. That is, for an HMM with $K$ states there is a $K$ by $K$ transition probability matrix $\Gamma$ with $\gamma_{i,j} = p(z_t=j | z_t=i)$. For the matrix to properly define a probability distribution, each row must be a simplex (i.e. its components must add up to $1$). 

Using our latent indicator variable approach for the case of two states, this can be written as: 

$$ 
\begin{equation}
  z_t \sim 
  \begin{cases}
    \text{Bern}(p_1) &\mbox{if } z_{t-1} = 1 \\
    \text{Bern}(p_2) &\mbox{if } z_{t-1} = 0 
  \end{cases}\; . 
\end{equation}
$$

A consequence of this formulation is that the amount of time $D_n$ spent in a given state $n$ (before switching to an other state) is a random variable that follows a geometric distribution with parameter $1 âˆ’ \gamma_{n,n}$.

We also have to define the initial state distribution $\boldsymbol\delta_n = p(z_1 = n)$.

Let's simulate a trajectory

```{r}
library(CircStats)

pal <- c("#f03b20","#2ca25f")

set.seed(1234)
T <- 200
a <- c(1, 5)   # scale for Weibull
b <- c(1, 2)   # shape for Weibull 
m <- c(pi, 0)  # circular mean for turns
rho <- c(0.5, 0.8)
p <- c(0.06, 0.8) # prob of z_t = 2 given z_t-1 = 1 and 2

MU <- matrix(0, T, 2)
z <- numeric(T)

phi <- runif(1, 0, 2 * pi) # initial movement direction

z[1] <- rbinom(1, size = 1, prob = p) + 1

for(t in 2:T){
  z[t] <- rbinom(1, size = 1, prob = p[z[t-1]]) + 1
  tmp <- rwrpcauchy(1, location = m[z[t]], rho = rho[z[t]])
  if (tmp > pi) 
    tmp <- tmp - 2 * pi
  if (tmp < -pi) 
    tmp <- tmp + 2 * pi
  phi <- phi + tmp
  s <- rweibull(1, shape = b[z[t]], scale = a[z[t]]) 
  move <- s * c(Re(exp((0+1i) * phi)), Im(exp((0+1i) * phi)))
  MU[t, ] <- MU[t-1, ] + move
}

plot(MU, type = "l", asp = 1, xlab = "", ylab = "", lwd = 1,
     cex.lab = 1.2, bty = "n", las = 1) 
for(i in 2:T){
  lines(MU[(i-1):i,], col = pal[z[i]], lwd = 2)
}

```

Lets look at the time series of states
```{r, fig.height=3, fig.width=7}

plot(z-1, type = "s", xlab = "time", ylab = "z", yaxt="n",
     cex.lab = 1.2, bty = "n", las = 1, mar=c(5,4,8,1)
     )
axis(side=2, at=c(0,1))

```

Now we fit an HMM (see `hmm.stan`)

```{r}
library(momentuHMM)
datos <- prepData(data.frame(MU),type="UTM",coordNames=c("X1","X2"))

# remove NAs
datos$step[is.na(datos$step)] <- -100
datos$angle[is.na(datos$angle)] <- -100
datos$ID <- as.numeric(datos$ID)

stan.data <- list(T = nrow(datos),
                  N = 2,
                  ID = datos$ID,
                  steps = datos$step,
                  turns = datos$angle,
                  lb = 0.8)

library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

fit <- stan(file = "Stan_code/hmm.stan", 
            data = stan.data,
            iter = 1000, 
            chains = 3
            )
```

As usual, we need to check that the chains have converged (`Rhat` $< 1.1$), and that we have a decent sample size of the posteriors (`n_eff`). Then we can look at the posteriors for the parameters governing steps and turns

```{r}
print(fit, pars = c("mu", "rho", "shape", "scale", "g"))
```

Let's plot the posteriors
```{r, fig.width=10}
plot(fit, pars = list("mu", "rho", "shape", "scale", "g"), 
     show_density = TRUE, ci_level = 0.5, fill_color = "gray")

```

We can compare posteriors to true parameter values
```{r}
m.pars <- rstan::extract(fit, pars = c("mu", "rho", "scale", "shape", "g"))

op <- par(mar = c(5, 4, 1, 2) + 0.1, cex.lab = 1.2, bty = "n", las = 1)

layout(matrix(1:10,2,5, byrow = TRUE))
plot(density(m.pars$mu[,1]), main="", xlab=expression(mu[1]))
abline(v=m[1], lwd=2)
plot(density(m.pars$mu[,2]), main="", xlab=expression(mu[2]))
abline(v=m[2], lwd=2)
plot(density(m.pars$rho[,1]), main="", xlab=expression(rho[1]))
abline(v=rho[1], lwd=2)
plot(density(m.pars$rho[,2]), main="", xlab=expression(rho[2]))
abline(v=rho[2], lwd=2)
plot(density(m.pars$scale[,1]), main="", xlab="scale")
abline(v=a[1], lwd=2)
plot(density(m.pars$scale[,2]), main="", xlab="scale")
abline(v=a[2], lwd=2)
plot(density(m.pars$shape[,1]), main="", xlab="shape")
abline(v=b[1], lwd=2)
plot(density(m.pars$shape[,2]), main="", xlab="shape")
abline(v=b[2], lwd=2)
plot(density(m.pars$g[,1,2]), main="", xlab="g 1 to 2")
abline(v=p[1], lwd=2)
plot(density(m.pars$g[,2,2]), main="", xlab="g 2 to 2")
abline(v=p[2], lwd=2)
```

The classsified trajectory
```{r}
psam <- rstan::extract(fit, pars = c("mu", "rho", "scale", "shape", "viterbi"))
states <- colMeans(psam$viterbi)
ggplot(datos, aes(x,y,group=ID,col=states)) + geom_point(size=0.5) +
  geom_path(size=0.5) + coord_equal()
```

Compare true states to estimated ones
```{r}
op <- par(cex.lab = 1.2 , font.lab = 1, cex.axis = 1, bty = "n", las = 1)
plot(jitter(z[-1]), states[-200], col = gray(0.5,0.5), pch=16, xlab = "jittered z", ylab = "mean posterior state" )
par(op)
```



# Diagnostics

Let's start by looking at the density of step and turn distributions. As we know the true parameters for these, we can add them to the plots.
```{r}
# restore NAs
datos$step[datos$step < 0] <- NA 
datos$angle[datos$angle < (-pi)] <- NA

# unpack posterior draws
shape.pos <- rstan::extract(fit, pars = "shape")$shape 
scale.pos <- rstan::extract(fit, pars = "scale")$scale
mu.pos <- rstan::extract(fit, pars = "mu")$mu
rho.pos <- rstan::extract(fit, pars = "rho")$rho


# indices of posterior draws to plot (thinned for visualisation purposes)
ind <- seq(1, nrow(shape.pos), by = 5)
# plot step length densities
stepgrid <- seq(min(datos$step, na.rm = TRUE),
                max(datos$step, na.rm = TRUE), length = 100)

plot(NA, xlim = c(0, 10), ylim = c(0, 1.1), 
     xlab = "step length", ylab = "density") 

for (i in ind) {
  lines(stepgrid, dweibull(stepgrid, shape = shape.pos[i, 1], scale = scale.pos[i, 1]),
        lwd = 0.2, col = adjustcolor(pal[1], alpha.f = 0.1))
  lines(stepgrid, dweibull(stepgrid, shape = shape.pos[i, 2], scale = scale.pos[i, 2]),
        lwd = 0.2, col = adjustcolor(pal[2], alpha.f = 0.1))
}

lines(stepgrid, dweibull(stepgrid, shape = b[1], scale = a[1]), lwd = 2)
lines(stepgrid, dweibull(stepgrid, shape = b[2], scale = a[2]), lwd = 2)

# plot turning angle densities
anglegrid <- seq(-pi, pi, length = 100)
plot(NA, xlim = c(-pi, pi), ylim = c(0, 1.6), 
     xlab = "turnging angle", ylab = "density") 

for (i in ind[-1]) {
  lines(anglegrid, dwrpcauchy(anglegrid, mu = mu.pos[i, 1], rho = rho.pos[i, 1]), 
         lwd = 0.2, col = adjustcolor(pal[1], alpha.f = 0.1))
  lines(anglegrid, dwrpcauchy(anglegrid, mu = mu.pos[i, 2], rho = rho.pos[i, 2]), 
         lwd = 0.2, col = adjustcolor(pal[2], alpha.f = 0.1))
}

lines(anglegrid, dwrpcauchy(anglegrid, mu=m[1], rho=rho[1]), lwd = 2)
lines(anglegrid, dwrpcauchy(anglegrid, mu=m[2], rho=rho[2]), lwd = 2)
```

Now a posterior predictive check on the autocorrelation in step lengths

```{r}
psam <- rstan::extract(fit, pars = c("mu", "rho", "scale", "shape", "viterbi"))

steps <- datos$step

n.sims <- nrow(psam$mu) 

ppsteps <- matrix(NA,n.sims,T)
#ppturns <- matrix(NA,n.sims,T)

p2 <- psam$viterbi
nobs <- ncol(p2)
scale <- psam$scale
shape <- psam$shape
mu <- psam$mu
rho <- psam$rho

for(i in 1:n.sims){
  z <- p2[i,]
  ppsteps[i,] = rweibull(T,shape=shape[i,z],scale=scale[i,z])  
#  ppturns[i,] = rwrpcauchy(T, location  = (mu[i,z]), rho = rho[i,z])
}

#Autocorrelation
nlags <- 61 
oac = acf(steps[2:(T-1)],lag.max=(nlags-1),plot=FALSE)  #  ACF observada

ppac = matrix(NA,n.sims,nlags)
for(i in 1:n.sims){
ppac[i,] = acf(ppsteps[i,],lag.max=(nlags-1),plot=FALSE)$acf
}

library(coda)
hpd <- HPDinterval(as.mcmc(ppac), prob = 0.9)

dat <- data.frame(y = 1:61, acf = as.numeric(oac$acf), 
                  lb = hpd[, 1], ub = hpd[, 2])
ggplot(dat, aes(y, acf)) + 
geom_ribbon(aes(x = y, ymin = lb, ymax = ub), fill = "grey70", alpha = 0.5) +
geom_point(col = "black", size = 1) + 
  geom_line() + 
coord_cartesian(xlim = c(2, 60), ylim = c(-0.2, 0.7)) + 
xlab("Lag") + ylab("ACF") + 
ggtitle("Observed Autocorrelation
          with 90% CI for ACF of Predicted Quantities")

``` 
