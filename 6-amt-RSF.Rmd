---
title: "amt-RSF"
author: "jmm"
date: "9/26/2020"
output:
  bookdown::html_document2:
    css: style.css
    number_sections: false
    theme: default
    highlight: haddock
    toc: true
    toc_float: true
bibliography: moves.bib
csl: ecology.csl
---

```{r, echo=FALSE}
library(knitr)
library(bookdown)
options(figure_counter = FALSE, digits = 2, width = 150)
opts_knit$set(eval.after='fig.cap')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), 
                      echo=TRUE, 
                      warning=FALSE, 
                      message=FALSE, 
                      fig.width=12, fig.height=4.5)
```

More material "borrowed" (and modified) from the [Movebank workshop](https://movebankworkshopraleighnc.netlify.app/index.html), led by [John Fieberg](https://fieberg-lab.cfans.umn.edu/people/john-fieberg).


Here we are going to use the package `amt` to perform a resource selection analysis (RSF). First, we load the necesary packages, and set the random number generator.

```{r}
library(lubridate)
library(raster)
library(move)
library(amt) 
library(broom)
library(nlme)
library(lme4)
library(here)
library(tidyverse)
nest <- nest_legacy
unnest <- unnest_legacy
set.seed(10299)
```

Now we load the data created in the previous exercise

```{r}
trk <- read_rds(here("data", "trk.Rdata"))
```

 ## RSF prep
 
Generate random points within a minimum convex polygon (mcp) for a single individual using `amt` functions.

Notes:
 
- It is common to generate points randomly, but other options are possible. 
- In particular, it can beneficial to generate a systematically placed sample.
- Samples can also be generated using the *spsample* function in the `sp` package or using a GIS (note: `amt` uses the `spsample` function within its function `random_points`)
 - Other home range polygons could be used (e.g., kernel density, local convex hull
 etc.). See how we used `rpoint` from the `spatstats` package to sample from a 99% KDE in [2-RSF](https://github.com/jmmorales/moves/blob/master/2-RSF.Rmd)
 
Currently `amt` only has mcp implemented in the `random_points` funtion.
 
#### Random points: illustrate for 1 individual

```{r}
trk %>% filter(id == "F1") %>%
  random_points(factor = 20) %>% 
  plot()
```

Illustrate systematic points
```{r}
trk %>% filter(id == "F1") %>% 
  random_points(factor = 20, type = "regular") %>% 
  plot() 
```

We can use just 1 random point for each observed point for better visualization.
```{r}
trk %>% filter(id=="F1") %>% 
  random_points(factor = 1, type="regular") %>% 
  plot() 
```

Now, let's generate points for all individuals. We can do this efficiently by making use of pipes (`%>%`), nested data frames, and then by adding a new column -- a list-column -- to `trks`

```{r}
avail.pts <- trk %>% 
  group_by(id) %>% 
  nest %>% 
  mutate(rnd_pts = map(data, ~ random_points(., factor=20))) %>% 
  select(id, rnd_pts) %>% 
  unnest()
```

Because unnesting loses the class, we will have to manually reset it
```{r}
class(avail.pts) <- c("random_points", class(avail.pts))
```

If you do not like pipes, you could do this using a loop (not evaluated)
```{r, eval=FALSE}
avail.pts <- NULL
uid <- unique(trk$id) # individual identifiers
luid <- length(uid) # number of unique individuals
for(i in 1:luid){
#  random_points will generate random points within mcp
#  Add on the individual id and combine all data
   temp <- cbind(id = uid[i], trk %>% filter(id==uid[i]) %>% random_points)
   avail.pts <- rbind(avail.pts, temp)
}
avail.pts <- as_tibble(avail.pts)
```

### Prepare environmental covariates
 
We will use three covariates: land use class, elevation, and human population density
```{r}
landuse <- raster(here("data/landuse/landuse_study_area.tif"))
elevation <- raster(here("data/elevation/ASTER ASTGTM2 Elevation-20100101120000000-0-0.tif"))
popden <- raster(here("data/pop_den/pop_den.tif"))
```

First, we need to bring all three layers to the same CRS using `projectRaster` from the `raster` package .
```{r}
get_crs(trk)
landuse <- projectRaster(landuse, crs = get_crs(trk), method = "ngb")
elevation <- projectRaster(elevation, crs = get_crs(trk))
popden <- projectRaster(popden, crs = get_crs(trk))
```

Now we plot the rasters
```{r}
plot(landuse)
plot(elevation)
plot(popden)
```
Assign each raster a meaningful name
```{r}
names(landuse) <- "landclass"
names(elevation) <- "ele"
names(popden) <- "popden"
```

Let's check the resolution of the rasters 

```{r}
res(landuse)
res(elevation)
res(popden)
```

Resolutions (and also extents) are different. This means, that we can not stack the rasters. We have two options: 

1. Resample rasters to the coarsest raster (popden) using the function `raster::resample`. 

2. Extract covariate values from each raster idendependetly. 

We will continue with second option.

```{r}
avail.pts <- avail.pts %>% 
  extract_covariates(landuse) %>%  
  extract_covariates(elevation) %>% 
  extract_covariates(popden)

avail.pts
```

Create landcover classes (as suggested by Scott Lapoint)

```{r}
rsfdat <- avail.pts %>%  
  mutate(landclass = as.character(landclass), 
  landC = fct_collapse(landclass,
      agri = c("81", "82"),
      forest =c("41", "42", "43"),
      shrub = c("52"),
      grass = c("31", "71"),
      wet = c("90", "95"),
      other = c("11", "21", "22", "23", "24")))
```

As usual, before doing any analyses, we center and scale the predicting variables. We also make the response (`case_`) numeric

```{r}
rsfdat <- rsfdat %>% 
  mutate(elev = scale(ele), 
         popD = scale(popden), 
         case_ = as.numeric(case_))
```

Save RSF data for later (multiple animals)
```{r}
write_rds(rsfdat, "data/rsf_dat.rds")
```

## Some data exploration

Look at distribution of habitat type for used and available observations

```{r, fig.width=8, fig.height=8 }
ggplot(rsfdat, aes(x=landC, y=..prop.., group=case_, colour=as.factor(case_) )) +
geom_bar(position="dodge", aes(fill = as.factor(case_) )) +
  facet_wrap(~id, scales = "free")

```

## RSF fitting

Weight available data. This is a trick for the logistic regression.
```{r}
rsfdat$w <- ifelse(rsfdat$case_ == 1, 1, 5000)
```


We can fit an RSF model to a single animal using logistic regression

```{r}
summary(glm(case_ ~ elev + popD + landC, data = subset(rsfdat, id == "M2"), 
            weight = w, family = binomial))
```

Note, this individual did not experience all landcover classes

```{r, fig.width=6, fig.height=4}
rsfdat %>% filter(id == "M2") %>% 
  with(table(case_, landC))  

rsfdat %>% filter(id == "M2") %>% 
  count(landC, case_) # this works with the amt development version
  
rsfdat$used<-as.factor(rsfdat$case_)
rsfdat$used<-fct_recode(rsfdat$used, "avail" = "0", "used" = "1")

ggplot(subset(rsfdat, id=="M2"),  
       aes(x=landC,group=used)) + 
  geom_bar(position=position_dodge(), 
           aes(y=..prop.., fill = used), stat="count") + 
  scale_fill_brewer(palette="Paired") + 
  geom_text(aes(label = scales::percent(..prop..), 
                y= ..prop.. ), 
            stat= "count", 
            vjust = -.3, position=position_dodge(0.9)) + 
  labs(y = "Proportion", fill="used", x="Landcover") 
```

Now, fit an RSF model to data from each animal. Since not all animals experience all habitat types, let's just explore forest versus non-forest

```{r}
rsfdat$forest <- ifelse(rsfdat$landC == "forest", 1, 0)

class(rsfdat) <- class(rsfdat)[-1] # this should be fixed in the dev version

rsffits <- rsfdat %>% 
  group_by(id) %>% 
  nest %>% 
  mutate(mod = map(data, 
                   function(x) glm(case_ ~ elev + popD + forest, 
                                   data = x, 
                                   weight = w, 
                                   family = binomial))) 
```
This stores a list of model fits in `rsffits`. 
Let's look at first model

```{r}
rsffits$mod[[1]]
```

Now, use `tidy` to extract information about the model fits into a nested data frame

```{r}
rsffits <- rsffits %>%
   dplyr::mutate(tidy = purrr::map(mod, broom::tidy),
                 n = purrr::map(data, nrow) %>% 
                   simplify())
rsffits 
rsffits$tidy
```

Now, create data frame with the coefficients, etc

```{r}
rsf_coefs<-rsffits %>% 
  unnest(tidy) %>% 
  select(-(std.error:p.value))
rsf_coefs
```

Plot coefficients
```{r, fig.width=12, fig.heigh=4}
rsf_coefs %>% 
  filter(term!="(Intercept)") %>% 
  ggplot(., aes(x=1, y=estimate)) + 
  geom_dotplot(binaxis="y", stackdir="center") + 
  geom_hline(yintercept=0) + 
  facet_wrap(~term, scales="free")
```

## Exercises

1- Pick an animal and check how many available points you need for the regression coefficients to stabilize.

2- Repeat the RSF analysis for one animal but using a regular sampling scheme for availability. Do you get the same results?


## Document Footer	
Session Information:	
```{r}
sessionInfo()	 
```